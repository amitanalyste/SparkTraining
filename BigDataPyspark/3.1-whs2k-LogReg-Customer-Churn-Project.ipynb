{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build a model that predicts whether or not a customer is going to churn\n",
    "#1. IMport pyspark\n",
    "#2. Import Data\n",
    "#3. Transform Data\n",
    "#4. Create Model\n",
    "#5. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/home/ubuntu/spark-2.2.0-bin-hadoop2.7')\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('LogProj').getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "os.getcwd()\n",
    "data_folder = '/home/ubuntu/data/raw'\n",
    "file_name = '/customer_churn.csv'\n",
    "data = spark.read.csv(data_folder+file_name, header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Names: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- Total_Purchase: double (nullable = true)\n",
      " |-- Account_Manager: integer (nullable = true)\n",
      " |-- Years: double (nullable = true)\n",
      " |-- Num_Sites: double (nullable = true)\n",
      " |-- Onboard_date: timestamp (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- Company: string (nullable = true)\n",
      " |-- Churn: integer (nullable = true)\n",
      "\n",
      "+-------+-------------+-----------------+-----------------+------------------+-----------------+------------------+--------------------+--------------------+-------------------+\n",
      "|summary|        Names|              Age|   Total_Purchase|   Account_Manager|            Years|         Num_Sites|            Location|             Company|              Churn|\n",
      "+-------+-------------+-----------------+-----------------+------------------+-----------------+------------------+--------------------+--------------------+-------------------+\n",
      "|  count|          900|              900|              900|               900|              900|               900|                 900|                 900|                900|\n",
      "|   mean|         null|41.81666666666667|10062.82403333334|0.4811111111111111| 5.27315555555555| 8.587777777777777|                null|                null|0.16666666666666666|\n",
      "| stddev|         null|6.127560416916251|2408.644531858096|0.4999208935073339|1.274449013194616|1.7648355920350969|                null|                null| 0.3728852122772358|\n",
      "|    min|   Aaron King|             22.0|            100.0|                 0|              1.0|               3.0|00103 Jeffrey Cre...|     Abbott-Thompson|                  0|\n",
      "|    max|Zachary Walsh|             65.0|         18026.01|                 1|             9.15|              14.0|Unit 9800 Box 287...|Zuniga, Clark and...|                  1|\n",
      "+-------+-------------+-----------------+-----------------+------------------+-----------------+------------------+--------------------+--------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()\n",
    "data.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Cameron Williams', 42.0, 11066.8, 0, 7.22, 8.0, datetime.datetime(2013, 8, 30, 7, 0, 40), '10265 Elizabeth Mission Barkerburgh, AK 89518', 'Harvey LLC', 1)\n",
      "('Kevin Mueller', 41.0, 11916.22, 0, 6.5, 11.0, datetime.datetime(2013, 8, 13, 0, 38, 46), '6157 Frank Gardens Suite 019 Carloshaven, RI 17756', 'Wilson PLC', 1)\n",
      "('Eric Lozano', 38.0, 12884.75, 0, 6.67, 12.0, datetime.datetime(2016, 6, 29, 6, 20, 7), '1331 Keith Court Alyssahaven, DE 90114', 'Miller, Johnson and Wallace', 1)\n",
      "('Phillip White', 42.0, 8010.76, 0, 6.71, 10.0, datetime.datetime(2014, 4, 22, 12, 43, 12), '13120 Daniel Mount Angelabury, WY 30645-4695', 'Smith Inc', 1)\n",
      "('Cynthia Norton', 37.0, 9191.58, 0, 5.56, 9.0, datetime.datetime(2016, 1, 19, 15, 31, 15), '765 Tricia Row Karenshire, MH 71730', 'Love-Jones', 1)\n"
     ]
    }
   ],
   "source": [
    "for row in data.head(5):\n",
    "    print(row[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform into Numerical Columns\n",
    "#Location - from string using one hot\n",
    "#Onboard_date - month\n",
    "#Onboard_date - year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42.0, 11066.8, 0, 7.22, 8.0, datetime.datetime(2013, 8, 30, 7, 0, 40), '10265 Elizabeth Mission Barkerburgh, AK 89518', 'Harvey LLC', 1, 2013, 8, 7)\n",
      "(41.0, 11916.22, 0, 6.5, 11.0, datetime.datetime(2013, 8, 13, 0, 38, 46), '6157 Frank Gardens Suite 019 Carloshaven, RI 17756', 'Wilson PLC', 1, 2013, 8, 0)\n",
      "+----------------+----+--------------+---------------+-----+---------+-------------------+--------------------+----------+-----+---------------+----------------+---------------+\n",
      "|           Names| Age|Total_Purchase|Account_Manager|Years|Num_Sites|       Onboard_date|            Location|   Company|Churn|Onboarding_year|Onboarding_month|Onboarding_hour|\n",
      "+----------------+----+--------------+---------------+-----+---------+-------------------+--------------------+----------+-----+---------------+----------------+---------------+\n",
      "|Cameron Williams|42.0|       11066.8|              0| 7.22|      8.0|2013-08-30 07:00:40|10265 Elizabeth M...|Harvey LLC|    1|           2013|               8|              7|\n",
      "|   Kevin Mueller|41.0|      11916.22|              0|  6.5|     11.0|2013-08-13 00:38:46|6157 Frank Garden...|Wilson PLC|    1|           2013|               8|              0|\n",
      "+----------------+----+--------------+---------------+-----+---------+-------------------+--------------------+----------+-----+---------------+----------------+---------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "root\n",
      " |-- Names: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- Total_Purchase: double (nullable = true)\n",
      " |-- Account_Manager: integer (nullable = true)\n",
      " |-- Years: double (nullable = true)\n",
      " |-- Num_Sites: double (nullable = true)\n",
      " |-- Onboard_date: timestamp (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- Company: string (nullable = true)\n",
      " |-- Churn: integer (nullable = true)\n",
      " |-- Onboarding_year: integer (nullable = true)\n",
      " |-- Onboarding_month: integer (nullable = true)\n",
      " |-- Onboarding_hour: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import (year, month, hour)\n",
    "\n",
    "new_data = data.withColumn(col=year('Onboard_date'),colName='Onboarding_year')\n",
    "new_data = new_data.withColumn(col=month('Onboard_date'),colName='Onboarding_month')\n",
    "new_data = new_data.withColumn(col=month('Onboard_date'),colName='Onboarding_month')\n",
    "new_data = new_data.withColumn(col=hour('Onboard_date'),colName='Onboarding_hour')\n",
    "\n",
    "for row in new_data.head(2):\n",
    "    print(row[1:15])\n",
    "    \n",
    "new_data.show(2)\n",
    "new_data.printSchema()\n",
    "\n",
    "\n",
    "#date_year = year(col= 'Onboard_date')\n",
    "#model = date_year.fit(data)\n",
    "#df_transformed1 = model.transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total_Purchase</th>\n",
       "      <th>Num_Sites</th>\n",
       "      <th>Years</th>\n",
       "      <th>Onboarding_year</th>\n",
       "      <th>Onboarding_month</th>\n",
       "      <th>Onboarding_hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Total_Purchase</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.00339</td>\n",
       "      <td>-0.00562317</td>\n",
       "      <td>-0.0246313</td>\n",
       "      <td>0.0448348</td>\n",
       "      <td>-0.00431726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Num_Sites</th>\n",
       "      <td>-0.00339</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0516417</td>\n",
       "      <td>-0.0327771</td>\n",
       "      <td>0.00845673</td>\n",
       "      <td>-0.0450561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Years</th>\n",
       "      <td>-0.00562317</td>\n",
       "      <td>0.0516417</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.0466239</td>\n",
       "      <td>0.0158553</td>\n",
       "      <td>-0.0167235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Onboarding_year</th>\n",
       "      <td>-0.0246313</td>\n",
       "      <td>-0.0327771</td>\n",
       "      <td>-0.0466239</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.0390766</td>\n",
       "      <td>0.0511536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Onboarding_month</th>\n",
       "      <td>0.0448348</td>\n",
       "      <td>0.00845673</td>\n",
       "      <td>0.0158553</td>\n",
       "      <td>-0.0390766</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.00356287</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Total_Purchase   Num_Sites       Years Onboarding_year  \\\n",
       "Total_Purchase                1    -0.00339 -0.00562317      -0.0246313   \n",
       "Num_Sites              -0.00339           1   0.0516417      -0.0327771   \n",
       "Years               -0.00562317   0.0516417           1      -0.0466239   \n",
       "Onboarding_year      -0.0246313  -0.0327771  -0.0466239               1   \n",
       "Onboarding_month      0.0448348  0.00845673   0.0158553      -0.0390766   \n",
       "\n",
       "                 Onboarding_month Onboarding_hour  \n",
       "Total_Purchase          0.0448348     -0.00431726  \n",
       "Num_Sites              0.00845673      -0.0450561  \n",
       "Years                   0.0158553      -0.0167235  \n",
       "Onboarding_year        -0.0390766       0.0511536  \n",
       "Onboarding_month                1     -0.00356287  "
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Feature Correlations\n",
    "\n",
    "from pyspark.sql.functions import corr, covar_pop\n",
    "important_columns = ['Total_Purchase','Num_Sites', 'Years',\n",
    "                  'Onboarding_year', 'Onboarding_month','Onboarding_hour']\n",
    "\n",
    "\n",
    "corr_df = pd.DataFrame(columns=important_columns, index=important_columns)\n",
    "for feature in important_columns:\n",
    "    for feature2 in important_columns:\n",
    "        #new_data.select(corr(feature,feature2)).show()\n",
    "        corr_df[feature2][feature] = new_data.select(corr(feature,feature2)).head()[0]\n",
    "corr_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total_Purchase</th>\n",
       "      <th>Num_Sites</th>\n",
       "      <th>Years</th>\n",
       "      <th>Onboarding_year</th>\n",
       "      <th>Onboarding_month</th>\n",
       "      <th>Onboarding_hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Total_Purchase</th>\n",
       "      <td>5.79512e+06</td>\n",
       "      <td>-14.3944</td>\n",
       "      <td>-17.2422</td>\n",
       "      <td>-190.067</td>\n",
       "      <td>376.65</td>\n",
       "      <td>-72.295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Num_Sites</th>\n",
       "      <td>-14.3944</td>\n",
       "      <td>3.11118</td>\n",
       "      <td>0.116023</td>\n",
       "      <td>-0.18532</td>\n",
       "      <td>0.0520543</td>\n",
       "      <td>-0.552822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Years</th>\n",
       "      <td>-17.2422</td>\n",
       "      <td>0.116023</td>\n",
       "      <td>1.62242</td>\n",
       "      <td>-0.190361</td>\n",
       "      <td>0.0704771</td>\n",
       "      <td>-0.148176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Onboarding_year</th>\n",
       "      <td>-190.067</td>\n",
       "      <td>-0.18532</td>\n",
       "      <td>-0.190361</td>\n",
       "      <td>10.2749</td>\n",
       "      <td>-0.437116</td>\n",
       "      <td>1.1406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Onboarding_month</th>\n",
       "      <td>376.65</td>\n",
       "      <td>0.0520543</td>\n",
       "      <td>0.0704771</td>\n",
       "      <td>-0.437116</td>\n",
       "      <td>12.1782</td>\n",
       "      <td>-0.0864889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Total_Purchase  Num_Sites      Years Onboarding_year  \\\n",
       "Total_Purchase      5.79512e+06   -14.3944   -17.2422        -190.067   \n",
       "Num_Sites              -14.3944    3.11118   0.116023        -0.18532   \n",
       "Years                  -17.2422   0.116023    1.62242       -0.190361   \n",
       "Onboarding_year        -190.067   -0.18532  -0.190361         10.2749   \n",
       "Onboarding_month         376.65  0.0520543  0.0704771       -0.437116   \n",
       "\n",
       "                 Onboarding_month Onboarding_hour  \n",
       "Total_Purchase             376.65         -72.295  \n",
       "Num_Sites               0.0520543       -0.552822  \n",
       "Years                   0.0704771       -0.148176  \n",
       "Onboarding_year         -0.437116          1.1406  \n",
       "Onboarding_month          12.1782      -0.0864889  "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covar_df = pd.DataFrame(columns=important_columns, index=important_columns)\n",
    "for feature in important_columns:\n",
    "    for feature2 in important_columns:\n",
    "        #new_data.select(corr(feature,feature2)).show()\n",
    "        covar_df[feature2][feature] = new_data.select(covar_pop(feature,feature2)).head()[0]\n",
    "covar_df.head()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DF Transformation to Spark format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "important_columns = ['Total_Purchase','Num_Sites', 'Years',\n",
    "                  'Onboarding_year', 'Onboarding_month','Onboarding_hour']\n",
    "assembler = VectorAssembler(inputCols=important_columns, outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Names: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- Total_Purchase: double (nullable = true)\n",
      " |-- Account_Manager: integer (nullable = true)\n",
      " |-- Years: double (nullable = true)\n",
      " |-- Num_Sites: double (nullable = true)\n",
      " |-- Onboard_date: timestamp (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- Company: string (nullable = true)\n",
      " |-- Churn: integer (nullable = true)\n",
      " |-- Onboarding_year: integer (nullable = true)\n",
      " |-- Onboarding_month: integer (nullable = true)\n",
      " |-- Onboarding_hour: integer (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output = assembler.transform(new_data)\n",
    "output.printSchema()\n",
    "final_data = output.select('features', 'Churn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test/Train Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+\n",
      "|summary|              Churn|\n",
      "+-------+-------------------+\n",
      "|  count|                626|\n",
      "|   mean|0.16613418530351437|\n",
      "| stddev|0.37249868666277897|\n",
      "|    min|                  0|\n",
      "|    max|                  1|\n",
      "+-------+-------------------+\n",
      "\n",
      "+-------+------------------+\n",
      "|summary|             Churn|\n",
      "+-------+------------------+\n",
      "|  count|               274|\n",
      "|   mean|0.1678832116788321|\n",
      "| stddev|0.3744464645429237|\n",
      "|    min|                 0|\n",
      "|    max|                 1|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = final_data.randomSplit([0.7,0.3])\n",
    "train_data.describe().show()\n",
    "test_data.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create LogReg Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "lr = LogisticRegression(labelCol='Churn', featuresCol='features')\n",
    "lr_trained = lr.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_lr_trained = lr.fit(final_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+------------------+\n",
      "|summary|              Churn|        prediction|\n",
      "+-------+-------------------+------------------+\n",
      "|  count|                626|               626|\n",
      "|   mean|0.16613418530351437|0.1182108626198083|\n",
      "| stddev|0.37249868666277897|0.3231158211320125|\n",
      "|    min|                0.0|               0.0|\n",
      "|    max|                1.0|               1.0|\n",
      "+-------+-------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_sum = lr_trained.summary\n",
    "training_sum.predictions.describe().show()\n",
    "test_results = lr_trained.evaluate(test_data)\n",
    "#test_results.areaUnderROC\n",
    "predictions = test_results.predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|            features|Churn|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|[3263.0,9.0,2.77,...|    0|[3.95641127730121...|[0.98122749947310...|       0.0|\n",
      "|[3825.7,8.0,4.28,...|    0|[4.29474072311952...|[0.98654344111046...|       0.0|\n",
      "|[4111.4,8.0,3.93,...|    0|[4.38964725858222...|[0.98774689677991...|       0.0|\n",
      "|[4316.73,9.0,4.79...|    0|[2.81333693405567...|[0.94339228630554...|       0.0|\n",
      "|[4492.44,9.0,6.43...|    0|[1.92253604480088...|[0.87242096881303...|       0.0|\n",
      "|[5024.52,9.0,8.11...|    1|[1.1508963597262,...|[0.75967460262709...|       0.0|\n",
      "|[5191.08,7.0,6.29...|    0|[4.93559820106940...|[0.99286511156548...|       0.0|\n",
      "|[5192.38,11.0,4.8...|    1|[0.48574492493590...|[0.61910353436706...|       0.0|\n",
      "|[5347.74,10.0,5.6...|    0|[1.08134308819845...|[0.74674806615457...|       0.0|\n",
      "|[5387.75,9.0,6.83...|    0|[1.72660908660769...|[0.84897817117087...|       0.0|\n",
      "|[5570.45,7.0,2.23...|    0|[6.57495278915565...|[0.99860707118718...|       0.0|\n",
      "|[5622.5,7.0,6.05,...|    0|[4.83469611466131...|[0.99211358634497...|       0.0|\n",
      "|[5647.92,8.0,5.08...|    0|[3.92800420351348...|[0.98069702242124...|       0.0|\n",
      "|[5695.21,7.0,4.1,...|    0|[5.68206660251299...|[0.99660505366360...|       0.0|\n",
      "|[5720.98,8.0,6.63...|    0|[3.15513074316435...|[0.95911041203887...|       0.0|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "only showing top 15 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "pred_and_labels = lr_trained.evaluate(test_data)\n",
    "pred_and_labels.predictions.show(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8258962623951182"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create the evaluator\n",
    "churn_eval = BinaryClassificationEvaluator(labelCol='Churn', rawPredictionCol='prediction')\n",
    "\n",
    "#Now pass in the dataframe we just created\n",
    "auc = churn_eval.evaluate(pred_and_labels.predictions)\n",
    "auc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Against New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"/new_customers.csv\"\n",
    "new_customers = spark.read.csv(data_folder+file_name, header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Names',\n",
       " 'Age',\n",
       " 'Total_Purchase',\n",
       " 'Account_Manager',\n",
       " 'Years',\n",
       " 'Num_Sites',\n",
       " 'Onboard_date',\n",
       " 'Location',\n",
       " 'Company',\n",
       " 'Onboarding_year',\n",
       " 'Onboarding_month',\n",
       " 'Onboarding_hour']"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_test = new_customers.withColumn(col=year('Onboard_date'),colName='Onboarding_year')\n",
    "new_test = new_test.withColumn(col=month('Onboard_date'),colName='Onboarding_month')\n",
    "new_test = new_test.withColumn(col=month('Onboard_date'),colName='Onboarding_month')\n",
    "new_test = new_test.withColumn(col=hour('Onboard_date'),colName='Onboarding_hour')\n",
    "new_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Names: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- Total_Purchase: double (nullable = true)\n",
      " |-- Account_Manager: integer (nullable = true)\n",
      " |-- Years: double (nullable = true)\n",
      " |-- Num_Sites: double (nullable = true)\n",
      " |-- Onboard_date: timestamp (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- Company: string (nullable = true)\n",
      " |-- Onboarding_year: integer (nullable = true)\n",
      " |-- Onboarding_month: integer (nullable = true)\n",
      " |-- Onboarding_hour: integer (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Transform Data to Spark Format\n",
    "important_columns = ['Total_Purchase','Num_Sites', 'Years',\n",
    "                  'Onboarding_year', 'Onboarding_month','Onboarding_hour']\n",
    "assembler = VectorAssembler(inputCols=important_columns, outputCol='features')\n",
    "output = assembler.transform(new_test)\n",
    "output.printSchema()\n",
    "final_results = lr_trained.transform(output)\n",
    "#output = output.withColumn(colName='Churn',col=(new_test['Years']*0))\n",
    "#final_test_data = output.select('features', 'Churn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------------------+--------------------+----------+\n",
      "|         Company|       rawPrediction|         probability|prediction|\n",
      "+----------------+--------------------+--------------------+----------+\n",
      "|        King Ltd|[2.36842530123786...|[0.91438766905519...|       0.0|\n",
      "|   Cannon-Benson|[-7.1171122599380...|[8.10448275527764...|       1.0|\n",
      "|Barron-Robertson|[-2.4965984285989...|[0.07609698712692...|       1.0|\n",
      "|   Sexton-Golden|[-5.6051194277756...|[0.00366549585534...|       1.0|\n",
      "|        Wood LLC|[1.10345072040642...|[0.75090610814763...|       0.0|\n",
      "|   Parks-Robbins|[-3.3125390808024...|[0.03514352120712...|       1.0|\n",
      "+----------------+--------------------+--------------------+----------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Names',\n",
       " 'Age',\n",
       " 'Total_Purchase',\n",
       " 'Account_Manager',\n",
       " 'Years',\n",
       " 'Num_Sites',\n",
       " 'Onboard_date',\n",
       " 'Location',\n",
       " 'Company',\n",
       " 'Onboarding_year',\n",
       " 'Onboarding_month',\n",
       " 'Onboarding_hour',\n",
       " 'features',\n",
       " 'rawPrediction',\n",
       " 'probability',\n",
       " 'prediction']"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_results.select('Company','rawPrediction','probability','prediction').show()\n",
    "final_results.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_results = lr_trained.evaluate(final_test_data)\n",
    "new_predictions = new_results.predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(new_predictions.head(201)[0][4])\n",
    "\n",
    "\n",
    "for pred in new_predictions.head(20):\n",
    "    print(pred[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
